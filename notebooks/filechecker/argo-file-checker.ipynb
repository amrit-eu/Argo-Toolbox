{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240168e3",
   "metadata": {},
   "source": [
    "## ðŸ§­ Argo FormatChecker Notebook (AMRIT Consortium)\n",
    "\n",
    "This notebook allows you to use the **Argo Format Checker** provided by  **AMRIT** to validate Argo NetCDF files.  \n",
    "The FormatChecker performs both **format** and **content** checks on Argo NetCDF files to ensure compliance with the Argo data standards.\n",
    "\n",
    "ðŸ“˜ **References:**\n",
    "- The Argo NetCDF format is defined in the [Argo Userâ€™s Manual](http://dx.doi.org/10.13155/29825).  \n",
    "- More details and documentation are available on the [Argo Data Management website](https://www.argodatamgt.org/Documentation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa8969d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d687b649",
   "metadata": {},
   "source": [
    "## The main steps to run the checker\n",
    "\n",
    "1. Setup \n",
    "    - before running this notebook, install dependencies with:\n",
    "    ```bash\n",
    "    pip install -r notebooks/requirements.txt\n",
    "    ```\n",
    "2. Run the complete notebook\n",
    "    - Imports necessary packages.\n",
    "    - Configures the API URL and DAC.\n",
    "        - Set the API_BASE_URL to where the File Checker API is running.\n",
    "        - If you are running the File Checker locally inside Docker, set it to the address where the \n",
    "            Docker container is exposing the API `http://localhost:8000`\n",
    "        - If you are running the File Checker in a Kubernetes cluster, use the cluster\n",
    "            URL where the service is exposed. For example:\n",
    "            `https://livkrakentst.clusters.bodc.me/ewetchy/amrit/argo-toolbox/api/file-checker`\n",
    "        - Only one of the URLs should be uncommented based on your environment.\n",
    "    - Sets the default DAC for validation.\n",
    "    - Checks the connectivity to the API.\n",
    "5. Checking files\n",
    "    - <p>If you need to check few selected files , select them by clicking on the <b>Upload</b> button.</p>\n",
    "6. Optionally run the checker on all files of a deployment.\n",
    "    - <p>If you want to check a whole deployment, select the path of the files and select <b> Run Deployment Check </b>.</p>\n",
    "7. Results are saved to a csv file.Result of first few are shown on the console.\n",
    "    - The name of the output file is part of configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1ï¸âƒ£ Importing necessary packages\n",
    "# ===============================\n",
    "\n",
    "import logging\n",
    "import tempfile\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display as ipy_display\n",
    "from ipywidgets import FileUpload, Label, Output, VBox\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "for handler in logger.handlers[:]:\n",
    "    logger.removeHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2ï¸âƒ£ Configuration\n",
    "# ===============================\n",
    "# Local Docker instance\n",
    "API_BASE_URL=\"http://localhost:8000\"\n",
    "\n",
    "# Kubernetes test instance\n",
    "# API_BASE_URL= \"https://livkrakentst.clusters.bodc.me/ewetchy/amrit/argo-toolbox/api/file-checker\"\n",
    "\n",
    "# Default DAC for validation\n",
    "DEFAULT_DAC = \"bodc\"\n",
    "\n",
    "# Mount location of all the deployment files\n",
    "# if you are running the API locally via Docker, ensure this path matches the volume mount in your Docker setup\n",
    "# for example docker  run --rm --name argo-file-checker2 -p 8000:8000 argo-file-checker\n",
    "\n",
    "# Result file for full deployment checks\n",
    "deployments_files_check_result_file=\"results/deployment_files_check_result.csv\"\n",
    "\n",
    "# Endpoints\n",
    "CHECK_FILE_ENDPOINT = \"/check-files\"\n",
    "FULL_DEPLOYMENT_CHECK_ENDPOINT = \"/check-deployment\"\n",
    "HEALTH_ENDPOINT = \"/\"\n",
    "\n",
    "# Request settings\n",
    "TIMEOUT = 30  # API request timeout in seconds\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "# Full URL for file check endpoint\n",
    "FILE_CHECK_URL = f\"{API_BASE_URL}/{CHECK_FILE_ENDPOINT}\"\n",
    "\n",
    "logger.info(\"ðŸ”— API Base URL:%s\",  API_BASE_URL)\n",
    "logger.info(\"ðŸ›ï¸ DAC: %s\" ,DEFAULT_DAC)\n",
    "# ============================================\n",
    "#  3ï¸âƒ£ function to test config and api\n",
    "# ============================================\n",
    "def test_api_connection() -> bool:\n",
    "    \"\"\"Test if the API is accessible.\"\"\"\n",
    "    logger.info(\"\\nðŸ” Testing API Connection..\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/\", timeout=5)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logger.exception(\"Could not connect to API. Is the container running?\")\n",
    "        return False\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.exception(\"Connection timed out\")\n",
    "        return False\n",
    "\n",
    "    except Exception:\n",
    "        logger.exception(\"Unexpected error\")\n",
    "        return False\n",
    "    else:\n",
    "        result = response.json()\n",
    "        logger.info(\"API is accessible!\")\n",
    "        logger.info(\"Health Check Response: %s\", result)\n",
    "        return True\n",
    "\n",
    "# ============================================\n",
    "#  4ï¸âƒ£ function to check the files\n",
    "# ============================================\n",
    "def prepare_files(file_paths:list[str])-> list[tuple[str, tuple[str, Any, str]]]:\n",
    "    \"\"\"Filechecker to check nc files.\"\"\"\n",
    "    files_data = []\n",
    "    for file_path in file_paths:\n",
    "        path = Path(file_path)\n",
    "        if not path.exists():\n",
    "            logger.warning(\"File not found: %s\",file_path)\n",
    "            continue\n",
    "\n",
    "        # Determine content type based on file extension\n",
    "        content_type = {\n",
    "            \".json\": \"application/json\",\n",
    "            \".nc\": \"application/x-netcdf\",\n",
    "        }.get(path.suffix, \"application/x-netcdf\")\n",
    "\n",
    "        try:\n",
    "            file_obj = path.open(\"rb\")\n",
    "            files_data.append((\"files\", (path.name, file_obj, content_type)))\n",
    "        except Exception:\n",
    "            logger.exception(\"Error opening  %s\",path)\n",
    "            continue\n",
    "    return files_data\n",
    "\n",
    "def send_file_check(files_data: list[tuple], dac: str) -> dict[str, Any] | None:\n",
    "    \"\"\"Send files to FILE_CHECK_URL and return structured result.\"\"\"\n",
    "    if not files_data:\n",
    "        logger.warning(\"No valid files to upload!\")\n",
    "\n",
    "    params = {\"dac\": dac}\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            FILE_CHECK_URL,\n",
    "            files=files_data,\n",
    "            params=params,\n",
    "            headers=HEADERS,\n",
    "            timeout=TIMEOUT,\n",
    "        )\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.exception(\"Request timed out after %s seconds\", TIMEOUT )\n",
    "\n",
    "    except requests.exceptions.RequestException:\n",
    "        logger.exception(\"Request error\")\n",
    "\n",
    "    except Exception:\n",
    "        logger.exception(\"Unexpected error\")\n",
    "\n",
    "    else:\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "\n",
    "        for _, (_, file_obj, _) in files_data:\n",
    "            file_obj.close()\n",
    "        try:\n",
    "            result = response.json()\n",
    "        except ValueError:\n",
    "            result = response.text\n",
    "\n",
    "        success = True\n",
    "\n",
    "        return {\n",
    "            \"success\": success,\n",
    "            \"status_code\": response.status_code,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"result\": result,\n",
    "        }\n",
    "    finally:\n",
    "        # This block runs no matter what, ensuring file handles are closed\n",
    "        for _, (_, file_obj, _) in files_data:\n",
    "                file_obj.close()\n",
    "\n",
    "# ============================================\n",
    "#  5ï¸âƒ£ function to check the whole deployment\n",
    "# ============================================\n",
    "# A mount was created for a whole deployment and that folder is passed.\n",
    "def file_check_deployment(deployment_files_folder:str, dac:str=DEFAULT_DAC)-> dict[str, Any] | None:\n",
    "    \"\"\"Filechecker to check nc files for a whole deployment.\"\"\"\n",
    "    logger.info(\"\\nðŸ” Checking full deployment in folder: %s\", deployment_files_folder)\n",
    "    # Check that folder exists\n",
    "    if not Path(deployment_files_folder).exists() or not Path(deployment_files_folder).is_dir():\n",
    "        logger.error(\"Deployment folder does not exist: %s\", deployment_files_folder)\n",
    "\n",
    "    # Count number of files in the folder\n",
    "    file_list = [str(f) for f in Path(deployment_files_folder).iterdir() if f.is_file()]\n",
    "    num_files = len(file_list)\n",
    "    logger.info(\"Number of files found in deployment folder: %d\", num_files)\n",
    "\n",
    "    if num_files == 0:\n",
    "        logger.warning(\"No files found in deployment folder: %s\", deployment_files_folder)\n",
    "\n",
    "    files_data = prepare_files(file_list)\n",
    "    return send_file_check(files_data, dac)\n",
    "\n",
    "# ==========================================\n",
    "#  5ï¸âƒ£ function to display the results and save to CSV\n",
    "# ============================================\n",
    "def show_result(result: dict, save_path: str | None = None) -> None:\n",
    "    \"\"\"Nicely display the result dict in Jupyter.\"\"\"\n",
    "    if not isinstance(result, dict):\n",
    "        logger.info(result)\n",
    "        return\n",
    "\n",
    "    results = result.get(\"result\", {}).get(\"results\", [])\n",
    "    if not results:\n",
    "        logger.info(\"No results found.\")\n",
    "        return\n",
    "\n",
    "    for r in results:\n",
    "        r[\"errors_messages\"] = \"\\n\".join(r.get(\"errors_messages\", []))\n",
    "        r[\"warnings_messages\"] = \"\\n\".join(r.get(\"warnings_messages\", []))\n",
    "    df = pd.DataFrame(results, columns=[\n",
    "        \"file\",\n",
    "        \"result\",\n",
    "        \"phase\",\n",
    "        \"errors_number\",\n",
    "        \"warnings_number\",\n",
    "        \"errors_messages\",\n",
    "        \"warnings_messages\",\n",
    "    ])\n",
    "\n",
    "    # Optional: Save to CSV\n",
    "    if save_path:\n",
    "        df.to_csv(save_path, index=False, encoding=\"utf-8\")\n",
    "        logger.info(\"âœ… Results saved to %s\",save_path)\n",
    "    logger.info(\"âœ… Results of first few files %s\",save_path)\n",
    "    ipy_display(df[:3])\n",
    "\n",
    "# Test 1: Check API connection\n",
    "api_available = test_api_connection()\n",
    "\n",
    "if not api_available:\n",
    "    logger.info(\"\\n API is not accessible. Please check:\")\n",
    "else:\n",
    "    logger.info(\"\\nðŸŽ‰ API is ready for use!\")\n",
    "# 2. Upload file(s) to test\n",
    "label = Label(\"(for checking few files) Please upload files to check:\")\n",
    "upload = FileUpload(accept=\".json,.nc\", multiple=True)\n",
    "out = Output()\n",
    "\n",
    "def on_upload_change(_change: dict[str, object]) -> None:\n",
    "    \"\"\"To handle file upload and trigger file check.\"\"\"\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        file_paths = []\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            for fileinfo in upload.value:\n",
    "                fname = fileinfo[\"name\"]\n",
    "\n",
    "                tmp_path = Path(tmp_dir) / fname\n",
    "                with Path(tmp_path).open(\"wb\") as f:\n",
    "                    f.write(fileinfo[\"content\"])\n",
    "                file_paths.append(tmp_path)\n",
    "\n",
    "\n",
    "            files_data = prepare_files(file_paths)\n",
    "            res= send_file_check(files_data, DEFAULT_DAC)\n",
    "            if res is not None:\n",
    "                show_result(res, save_path=\"file_check_results.csv\")\n",
    "            else:\n",
    "                logger.error(\"File check failed, nothing to display\")\n",
    "\n",
    "upload.observe(on_upload_change, names=\"value\")\n",
    "ipy_display(VBox([label, upload, out]))\n",
    "# Create a text input widget for the deployment folder\n",
    "\n",
    "deployment_folder_widget = widgets.Text(\n",
    "        value=\"//wsl.localhost/Ubuntu/home/vidkri/argo_mount\",  # default value\n",
    "        placeholder=\"Enter path to deployment folder\",\n",
    "        description=\"Enter path to deployment folder:\",\n",
    "        layout=widgets.Layout(width=\"90%\"),\n",
    "        style={\"description_width\": \"200px\"},\n",
    "    )\n",
    "\n",
    "# Create a button to trigger the check\n",
    "\n",
    "run_button = widgets.Button(description=\"Run complete deployment Check\", button_style=\"success\")\n",
    "\n",
    "# Define button click handler\n",
    "def on_run_button_clicked(_b:dict[str, object]) -> None:\n",
    "    \"\"\"Handle deployment check on button click.\"\"\"\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        deployment_folder = deployment_folder_widget.value.strip()\n",
    "        if not Path(deployment_folder).exists():\n",
    "            logger.warning(\"Folder does not exist: %s\" , deployment_folder)\n",
    "            return\n",
    "        # Run your deployment check\n",
    "        start = time.perf_counter()\n",
    "        result = file_check_deployment(deployment_folder, DEFAULT_DAC)\n",
    "        end = time.perf_counter()\n",
    "        elapsed_time = end - start\n",
    "\n",
    "        logger.info(\"Full deployment check result is saved to a file :%s\", deployments_files_check_result_file)\n",
    "        if result is not None:\n",
    "            logger.info(\"Checking full deployment took %s seconds\", elapsed_time)\n",
    "            show_result(result, deployments_files_check_result_file)\n",
    "        else:\n",
    "            logger.error(\"Deployment file check for the deployment failed\")\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# Link button to handler\n",
    "run_button.on_click(on_run_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(deployment_folder_widget, run_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
