{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240168e3",
   "metadata": {},
   "source": [
    "## üß≠ Argo FormatChecker Notebook (AMRIT Consortium)\n",
    "\n",
    "This notebook allows you to use the **Argo Format Checker** provided by  **AMRIT** to validate Argo NetCDF files.  \n",
    "The FormatChecker performs both **format** and **content** checks on Argo NetCDF files to ensure compliance with the Argo data standards.\n",
    "\n",
    "üìò **References:**\n",
    "- The Argo NetCDF format is defined in the [Argo User‚Äôs Manual](http://dx.doi.org/10.13155/29825).  \n",
    "- More details and documentation are available on the [Argo Data Management website](https://www.argodatamgt.org/Documentation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687b649",
   "metadata": {},
   "source": [
    "## The main steps to run the checker\n",
    "\n",
    "1. Run the cells which import necessary packages.\n",
    "2. Configure the API URL and DAC.\n",
    "   > Run the cells which define the various helper functions.\n",
    "3. Run the health check to verify connectivity.\n",
    "4. Upload .json or .nc files using the upload button.\n",
    "5. Optionally run the checker on all files of a deployment.\n",
    "5. Review results in the table or the output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ddcb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1Ô∏è‚É£ Importing necessary packages\n",
    "# ===============================\n",
    "\n",
    "import requests\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from ipywidgets import FileUpload, Button, VBox, Output\n",
    "from IPython.display import display, HTML\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "logger = logging.getLogger(\"filechecker\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(ch)\n",
    "logger.propagate = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b260a76",
   "metadata": {},
   "source": [
    "# File Checker Environment Setup\n",
    "===============================\n",
    "\n",
    "1. Set the API_BASE_URL to where the File Checker API is running.\n",
    " - If you are running the File Checker locally inside Docker, set it to the address where the \n",
    "   Docker container is exposing the API `http://localhost:8000`\n",
    " - If you are running the File Checker in a Kubernetes cluster, use the cluster\n",
    "   URL where the service is exposed. For example:\n",
    "   `https://livkrakentst.clusters.bodc.me/ewetchy/amrit/argo-toolbox/api/file-checker`\n",
    " - Only one of the URLs should be uncommented based on your environment.\n",
    "2. Set the default DAC for validation.\n",
    "3. Do NOT run other cells until you configure this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5820cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîó API Base URL:http://localhost:8000\n",
      "üèõÔ∏è DAC: bodc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 2Ô∏è‚É£ Configuration\n",
    "# ===============================\n",
    "# Local Docker instance\n",
    "API_BASE_URL=\"http://localhost:8000\"\n",
    "\n",
    "# Kubernetes test instance\n",
    "# API_BASE_URL= \"https://livkrakentst.clusters.bodc.me/ewetchy/amrit/argo-toolbox/api/file-checker\"\n",
    "\n",
    "# Default DAC for validation\n",
    "DEFAULT_DAC = \"bodc\"\n",
    "\n",
    "# Mount location of all the deployment files\n",
    "# if you are running the API locally via Docker, ensure this path matches the volume mount in your Docker setup\n",
    "# for example docker  run --rm --name argo-file-checker2 -p 8000:8000 argo-file-checker\n",
    "\n",
    "# Result file for full deployment checks\n",
    "deployments_files_check_result_file=\"deployment_files_check_result.csv\"\n",
    "\n",
    "# Endpoints\n",
    "CHECK_FILE_ENDPOINT = \"/check-files\"\n",
    "FULL_DEPLOYMENT_CHECK_ENDPOINT = \"/check-deployment\"\n",
    "HEALTH_ENDPOINT = \"/\"\n",
    "\n",
    "# Request settings\n",
    "TIMEOUT = 30  # API request timeout in seconds\n",
    "HEADERS = {\n",
    "    \"accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Full URL for file check endpoint\n",
    "FILE_CHECK_URL = f\"{API_BASE_URL}/{CHECK_FILE_ENDPOINT}\"\n",
    "\n",
    "logger.info(\"üîó API Base URL:%s\",  API_BASE_URL)\n",
    "logger.info(\"üèõÔ∏è DAC: %s\" ,DEFAULT_DAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a5fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  3Ô∏è‚É£ function to test config and api\n",
    "# ============================================\n",
    "def test_api_connection() -> bool:\n",
    "    \"\"\"Test if the API is accessible.\"\"\"\n",
    "    logger.info(\"\\nüîç Testing API Connection..\")\n",
    "    logger.info(\"-\" * 30)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"{API_BASE_URL}/\", timeout=5)\n",
    "        if response.status_code != 200:\n",
    "            logger.info(\"API returned status code: %s\",response.status_code)\n",
    "            return False\n",
    "        else:\n",
    "            result = response.json()\n",
    "            logger.info(\"API is accessible!\")\n",
    "            logger.info(\"Health Check Response: %s\",result)\n",
    "            return True\n",
    "\n",
    "\n",
    "\n",
    "    except requests.exceptions.ConnectionError as error:\n",
    "        logger.info(\"Could not connect to API. Is the container running?\")\n",
    "        logger.info(error)\n",
    "        return False\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.info(\"Connection timed out\")\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Unexpected error\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b3891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  4Ô∏è‚É£ function to check the files\n",
    "# ============================================\n",
    "def file_check(file_paths:list[str], dac:str=DEFAULT_DAC)-> dict[str, Any]:\n",
    "    \"\"\"Filechecker to check nc files.\"\"\"\n",
    "    files_data = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        path = Path(file_path)\n",
    "        if not path.exists():\n",
    "            logger.info(\"File not found: %s\",file_path)\n",
    "            continue\n",
    "\n",
    "        # Determine content type based on file extension\n",
    "        content_type = {\n",
    "            \".json\": \"application/json\",\n",
    "            \".nc\": \"application/octet-stream\",\n",
    "        }.get(path.suffix, \"application/octet-stream\")\n",
    "\n",
    "        try:\n",
    "            file_obj = path.open(\"rb\")\n",
    "            files_data.append((\"files\", (path.name, file_obj, content_type)))\n",
    "        except Exception as e:\n",
    "            logger.exception(\"Error opening  %s\",path)\n",
    "            continue\n",
    "\n",
    "    if not files_data:\n",
    "        logger.info(\"No valid files to upload!\")\n",
    "        return {\"success\": False, \"error\": \"no files to upload\"}\n",
    "\n",
    "    params = {\"dac\": dac}\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "\n",
    "        response = requests.post(\n",
    "            FILE_CHECK_URL,\n",
    "            files=files_data,\n",
    "            params=params,\n",
    "            headers=HEADERS,\n",
    "            timeout=TIMEOUT,\n",
    "        )\n",
    "    except requests.exceptions.Timeout:\n",
    "        logger.info(\"Request timed out after %s seconds\", TIMEOUT )\n",
    "        return {\"success\": False, \"error\": \"timeout\"}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.info(\"Request error: {e}\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Unexpected error\")\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "    else:\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "\n",
    "        for _, (_, file_obj, _) in files_data:\n",
    "            file_obj.close()\n",
    "        result = response.json() if response.status_code == 200 else response.text\n",
    "        success = response.status_code == 200\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"success\": success,\n",
    "            \"status_code\": response.status_code,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"result\": result,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a1ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "#  5Ô∏è‚É£ function to check the whole deployment\n",
    "# ============================================\n",
    "# A mount was created for a whole deployment and that folder is passed.\n",
    "# Send POST request\n",
    "def file_check_deployment(deployment_files_folder:str, dac:str=DEFAULT_DAC)-> dict[str, Any]:\n",
    "    \"\"\"Filechecker to check nc files for a whole deployment.\"\"\"\n",
    "    logger.info(\"\\nüîç Checking full deployment in folder: %s\", deployment_files_folder)\n",
    "    # Check that folder exists\n",
    "    if not Path(deployment_files_folder).exists() or not Path(deployment_files_folder).is_dir():\n",
    "        logger.error(\"Deployment folder does not exist: %s\", deployment_files_folder)\n",
    "        return {\"success\": False, \"error\": \"folder not found\"}\n",
    "\n",
    "    # Count number of files in the folder\n",
    "    file_list = [str(f) for f in Path(deployment_files_folder).iterdir() if f.is_file()]\n",
    "    num_files = len(file_list)\n",
    "    logger.info(\"Number of files found in deployment folder: %d\", num_files)\n",
    "\n",
    "    if num_files == 0:\n",
    "        return {\"success\": False, \"error\": \"no files found in deployment folder\"}\n",
    "\n",
    "    return file_check(file_list, dac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3be623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "#  5Ô∏è‚É£ function to display the results and save to CSV\n",
    "# ============================================\n",
    "def show_result(result: dict, save_path: str | None = None) -> None:\n",
    "    \"\"\"Nicely display the result dict in Jupyter.\"\"\"\n",
    "    if not isinstance(result, dict):\n",
    "        logger.info(result)\n",
    "        return\n",
    "\n",
    "    results = result.get(\"result\", {}).get(\"results\", [])\n",
    "    if not results:\n",
    "        logger.info(\"No results found.\")\n",
    "        return\n",
    "\n",
    "    for r in results:\n",
    "        r[\"errors_messages\"] = \"\\n\".join(r.get(\"errors_messages\", []))\n",
    "        r[\"warnings_messages\"] = \"\\n\".join(r.get(\"warnings_messages\", []))\n",
    "    df = pd.DataFrame(results, columns=[\n",
    "        \"file\",\n",
    "        \"result\",\n",
    "        \"phase\",\n",
    "        \"errors_number\",\n",
    "        \"warnings_number\",\n",
    "        \"errors_messages\",\n",
    "        \"warnings_messages\",\n",
    "    ])\n",
    "\n",
    "    # Optional: Save to CSV\n",
    "    if save_path:\n",
    "        df.to_csv(save_path, index=False, encoding=\"utf-8\")\n",
    "        logger.info(\"‚úÖ Results saved to %s\",save_path)\n",
    "   # CSS style for borders and wrapping\n",
    "    styles = \"\"\"\n",
    "    <style>\n",
    "        table {\n",
    "            border: 1px solid black;\n",
    "            border-collapse: collapse;\n",
    "        }\n",
    "        th, td {\n",
    "            border: 1px solid black !important;\n",
    "            padding: 5px;\n",
    "            text-align: left;\n",
    "            vertical-align: top;\n",
    "            max-width: 400px;\n",
    "            white-space: pre-wrap;\n",
    "            word-wrap: break-word;\n",
    "        }\n",
    "        th {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "\n",
    "    html_table = df.to_html(escape=False).replace(\"\\\\n\", \"<br>\")\n",
    "    display(HTML(styles + html_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531eb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44332495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing API Connection..\n",
      "------------------------------\n",
      "API is accessible!\n",
      "Health Check Response: {'status': 'OK'}\n",
      "\n",
      "üéâ API is ready for testing!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check API connection\n",
    "api_available = test_api_connection()\n",
    "\n",
    "if not api_available:\n",
    "    logger.info(\"\\nAPI is not accessible. Please check:\")\n",
    "else:\n",
    "    logger.info(\"\\nüéâ API is ready for testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499eb86e",
   "metadata": {},
   "source": [
    "<h3>üìù Instructions</h3>\n",
    "<p>Click the <b>Upload</b> button below and select the files you want to check.</p>\n",
    "<p>You can select multiple files from your computer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "585b1b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ba1677766f44d4b128584d9b7b655e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.json,.nc', description='Upload', multiple=True), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Upload file(s) to test\n",
    "upload = FileUpload(accept='.json,.nc', multiple=True)\n",
    "out = Output()\n",
    "\n",
    "def on_upload_change(change):\n",
    "    file_paths = []\n",
    "    for fileinfo in upload.value:\n",
    "        fname = fileinfo[\"name\"]\n",
    "        tmp_path = f\"/tmp/{fname}\"\n",
    "        with open(tmp_path, \"wb\") as f:\n",
    "            f.write(fileinfo[\"content\"])\n",
    "        file_paths.append(tmp_path)\n",
    "\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        logger.info(\"Selected files: %s\",file_paths)\n",
    "        res=file_check(file_paths)\n",
    "        show_result(res, save_path=\"file_check_results.csv\")\n",
    "\n",
    "upload.observe(on_upload_change, names=\"value\")\n",
    "\n",
    "display(VBox([upload, out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fade1",
   "metadata": {},
   "source": [
    "## Next to run the file checker on a whole deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bfcfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e36c9951fb04b06a8a4dd324b5b846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='//wsl.localhost/Ubuntu/home/vidkri/argo_mount', description='Deployment Folder:', layout=Layout(wi‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98b8d12908848328a7d142a026625d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Run Deployment Check', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a7d41cb2314a778f1f285da9c0dd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a text input widget for the deployment folder\n",
    "\n",
    "deployment_folder_widget = widgets.Text(\n",
    "        value=\"//wsl.localhost/Ubuntu/home/vidkri/argo_mount\",  # default value\n",
    "        placeholder=\"Enter path to deployment folder\",\n",
    "        description=\"Deployment Folder:\",\n",
    "        layout=widgets.Layout(width=\"90%\"),\n",
    "    )\n",
    "\n",
    "# Create a button to trigger the check\n",
    "\n",
    "run_button = widgets.Button(description=\"Run Deployment Check\", button_style=\"success\")\n",
    "\n",
    "# Define button click handler\n",
    "def on_run_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        deployment_folder = deployment_folder_widget.value.strip()\n",
    "        if not Path(deployment_folder).exists():\n",
    "            print(f\"Folder does not exist: {deployment_folder}\")\n",
    "            return\n",
    "        # Run your deployment check\n",
    "        result = file_check_deployment(deployment_folder, DEFAULT_DAC)\n",
    "        logger.info(\"\\nüìÇ Full deployment check result:%s\", result)\n",
    "        show_result(result, deployments_files_check_result_file)\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# Link button to handler\n",
    "run_button.on_click(on_run_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(deployment_folder_widget, run_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
